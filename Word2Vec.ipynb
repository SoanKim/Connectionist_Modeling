{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of 200125 Wikipedia.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8dNPfjP28Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdirve/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGf1EW-YDB7V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "while(1):\n",
        "    a.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPEnJjWUCQhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import tensorflow as tf\n",
        "# tf.test.gpu_device_name()\n",
        "!cat /proc/meminfo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARSLI0uUrpQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_d3WORlRgGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt-get install curl git\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "!pip install Mecab\n",
        "!pip install konlpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3KiDAUb0sqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install EchoTorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0YXUFZeCLUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-*- coding: utf-8 -*-\n",
        "import torch\n",
        "from torch import autograd, nn\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline\n",
        "import datetime as dt\n",
        "import itertools\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import codecs\n",
        "import re\n",
        "import logging\n",
        "import datetime\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from gensim.models.doc2vec import Doc2Vec as w\n",
        "from gensim import utils, matutils\n",
        "from numpy import exp, dot, zeros, outer, random, dtype, get_include, float32 as REAL,\\\n",
        "     uint32, seterr, array, uint8, vstack, argsort, fromstring, sqrt, newaxis, ndarray, empty, sum as np_sum\n",
        "from konlpy.tag import Mecab\n",
        "import argparse\n",
        "import base64\n",
        "import sys\n",
        "from gensim.models import Word2Vec\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VynJj_yCcsMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_kor1 = [] #wiki\n",
        "with open ('/content/gdirve/My Drive/wiki.txt', mode='r', encoding='utf-8') as file:\n",
        "  lines = file.readlines()\n",
        "  for line in lines:\n",
        "      raw_kor1.append(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytr127Hmw9yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_kor2 = [] #sejong\n",
        "with open ('/content/gdirve/My Drive/written_spoken_corpus.txt', mode='r', encoding='utf-8') as file:\n",
        "  lines = file.readlines()\n",
        "  for line in lines:\n",
        "    parsed = line.split('.')\n",
        "    for p in parsed:\n",
        "      raw_kor2.append(p+'.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cZGclOjMehO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref_pat = r'&lt;ref\\s*\\w*=*&\\w*;*'\n",
        "web_pat = r'https*://[a-z0-9]+.[a-z0-9]+.[a-z0-9]*.[a-z0-9]*/*[a-z0-9]*'\n",
        "foot_pat = r'_{1, 10}[0-9]{1, 20}'\n",
        "num_pat = r'[0-9][0-9][0-9][0-9][0-9]+'\n",
        "\n",
        "clean_li = []\n",
        "for raw in raw_kor1:\n",
        "\n",
        "    clean = re.sub('\\[', '', raw)\n",
        "    clean = re.sub('\\]', '', clean)\n",
        "    clean = re.sub('분류:', '', clean)\n",
        "    clean = re.sub('</text>', '', clean)\n",
        "    clean = re.sub('\\n', '', clean)\n",
        "    clean = re.sub(' 분류 : ', '', clean)\n",
        "    clean = re.sub('썸네일', '', clean)\n",
        "    clean = re.sub('웹 인용', '', clean)\n",
        "    clean = re.sub(ref_pat, '', clean)\n",
        "    clean = re.sub(web_pat, '', clean)\n",
        "    clean = re.sub(foot_pat, '', clean)\n",
        "    clean = re.sub(num_pat, '', clean)\n",
        "    #clean = re.sub('\\W+', ' ', clean)\n",
        "    clean = re.sub('[^a-zA-Z0-9가-힣.,?!]+', ' ', clean)\n",
        "    clean = re.sub('[a-zA-Z]+', ' ', clean)\n",
        "    clean = re.sub('\\s{2,100}', '', clean)\n",
        "    clean = re.sub('.{2, 100}', '', clean)\n",
        "    if clean.startswith('파일'):\n",
        "      clean = None\n",
        "    elif clean[-2:-1]=='|':\n",
        "      clean = None\n",
        "    else:\n",
        "      clean_li.append(clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vfbonmojCAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_li[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBH9M6rTmL2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(clean_li)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbBZoVyPmQuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(raw_kor1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GG2axMBmXvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(clean_li)+len(raw_kor1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw_vUovddYOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_kor3 = []\n",
        "def tokenize(list1, list2):\n",
        "    tagger = Mecab()\n",
        "    for lines1 in list1:\n",
        "    #s= \" \".join(tagger.morphs(sentence))\n",
        "      raw_kor3.append((' ').join(tagger.morphs(lines1)))\n",
        "    for lines2 in list2:\n",
        "      raw_kor3.append((' ').join(tagger.morphs(lines2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ddti5bneyky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenize(clean_li, raw_kor2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgZQDDwqVKx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import utils\n",
        "print(\"Total words in text: {}\".format(len(raw_kor3)))\n",
        "print(\"Unique words: {}\".format(len(set(raw_kor3)))) # `set` removes any duplicate words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAl1eFqObJrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "li = [] \n",
        "for w in raw_kor3:\n",
        "    word = re.sub('\\n', '', w)\n",
        "    li.append(word)\n",
        "st = ''\n",
        "for w in li:\n",
        "    # word = w.split()\n",
        "    st+=w\n",
        "print(st[0:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKDh_lazXznj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def preprocess(text):\n",
        "    words = text.split()\n",
        "    word_counts = Counter(words)\n",
        "    trimmed_words = [word for word in words if word_counts[word] > 5]\n",
        "\n",
        "    return trimmed_words\n",
        "\n",
        "def get_batches(int_text, batch_size, seq_length):\n",
        "    \"\"\"\n",
        "    Return batches of input and target\n",
        "    :param int_text: Text with the words replaced by their ids\n",
        "    :param batch_size: The size of batch\n",
        "    :param seq_length: The length of sequence\n",
        "    :return: A list where each item is a tuple of (batch of input, batch of target).\n",
        "    \"\"\"\n",
        "    n_batches = int(len(int_text) / (batch_size * seq_length))\n",
        "\n",
        "    # Drop the last few characters to make only full batches\n",
        "    xdata = np.array(int_text[: n_batches * batch_size * seq_length])\n",
        "    ydata = np.array(int_text[1: n_batches * batch_size * seq_length + 1])\n",
        "\n",
        "    x_batches = np.split(xdata.reshape(batch_size, -1), n_batches, 1)\n",
        "    y_batches = np.split(ydata.reshape(batch_size, -1), n_batches, 1)\n",
        "\n",
        "    return list(zip(x_batches, y_batches))\n",
        "\n",
        "\n",
        "def create_lookup_tables(words):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param words: Input list of words\n",
        "    :return: A tuple of dicts.  The first dict....\n",
        "    \"\"\"\n",
        "    word_counts = Counter(words)\n",
        "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
        "\n",
        "    return vocab_to_int, int_to_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zYtIZLCZcYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = preprocess(st)\n",
        "print(words[:30])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5cjsg3zXSA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_to_int, int_to_vocab = create_lookup_tables(words)\n",
        "int_words = [vocab_to_int[word] for word in words]\n",
        "\n",
        "print(int_words[:30])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nMbnQGmZOWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "threshold = 1e-5 #2.71828\n",
        "word_counts = Counter(int_words)\n",
        "#print(list(word_counts.items())[0])  # dictionary of int_words, how many times they appear\n",
        "\n",
        "total_count = len(int_words)\n",
        "freqs = {word: count/total_count for word, count in word_counts.items()}\n",
        "p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts}\n",
        "train_words = [word for word in int_words if random.random() < (1 - p_drop[word])]\n",
        "\n",
        "print(train_words[:30])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSYiLaImisGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_target(words, idx, window_size=5):\n",
        "    ''' Get a list of words in a window around an index. '''\n",
        "    \n",
        "    R = np.random.randint(1, window_size+1)\n",
        "    start = idx - R if (idx - R) > 0 else 0\n",
        "    stop = idx + R\n",
        "    target_words = words[start:idx] + words[idx+1:stop+1]\n",
        "    \n",
        "    return list(target_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqz8j-_ciseX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run this cell multiple times to check for random window selection\n",
        "int_text = [i for i in range(10)]\n",
        "print('Input: ', int_text)\n",
        "idx=5 # word index of interest\n",
        "\n",
        "target = get_target(int_text, idx=idx, window_size=5)\n",
        "print('Target: ', target)  # you should get some indices around the idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLF17oNSitFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(words, batch_size, window_size=5):\n",
        "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
        "    \n",
        "    n_batches = len(words)//batch_size\n",
        "    \n",
        "    # only full batches\n",
        "    words = words[:n_batches*batch_size]\n",
        "    \n",
        "    for idx in range(0, len(words), batch_size):\n",
        "        x, y = [], []\n",
        "        batch = words[idx:idx+batch_size]\n",
        "        for ii in range(len(batch)):\n",
        "            batch_x = batch[ii]\n",
        "            batch_y = get_target(batch, ii, window_size)\n",
        "            y.extend(batch_y)\n",
        "            x.extend([batch_x]*len(batch_y))\n",
        "        yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSp7vha2jH4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_text = [i for i in range(20)]\n",
        "x,y = next(get_batches(int_text, batch_size=4, window_size=5))\n",
        "\n",
        "print('x\\n', x)\n",
        "print('y\\n', y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HNvtCLpjIPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(embedding, valid_size=16, valid_window=100, device='gpu'):\n",
        "    embed_vectors = embedding.weight\n",
        "    magnitudes = embed_vectors.pow(2).sum(dim=1).sqrt().unsqueeze(0)\n",
        "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
        "    valid_examples = np.append(valid_examples,\n",
        "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
        "    valid_examples = torch.LongTensor(valid_examples).to(device)\n",
        "    \n",
        "    valid_vectors = embedding(valid_examples)\n",
        "    similarities = torch.mm(valid_vectors, embed_vectors.t())/magnitudes\n",
        "        \n",
        "    return valid_examples, similarities"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6ZVZ3-cjVyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDbandG4jWHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SkipGramNeg(nn.Module):\n",
        "    def __init__(self, n_vocab, n_embed, noise_dist=None):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.n_vocab = n_vocab\n",
        "        self.n_embed = n_embed\n",
        "        self.noise_dist = noise_dist\n",
        "        \n",
        "        self.in_embed = nn.Embedding(n_vocab,n_embed)\n",
        "        self.out_embed = nn.Embedding(n_vocab,n_embed)\n",
        "        \n",
        "        self.in_embed.weight.data.uniform_(-1,1)\n",
        "        self.out_embed.weight.data.uniform_(-1,1)\n",
        "        \n",
        "    def forward_input(self, input_words):\n",
        "        input_vector = self.in_embed(input_words)\n",
        "        return input_vector\n",
        "    \n",
        "    def forward_output(self, output_words):\n",
        "        output_vector = self.out_embed(output_words)\n",
        "\n",
        "        return output_vector\n",
        "    \n",
        "    def forward_noise(self, batch_size, n_samples):\n",
        "        \"\"\" Generate noise vectors with shape (batch_size, n_samples, n_embed)\"\"\"\n",
        "        if self.noise_dist is None:\n",
        "            noise_dist = torch.ones(self.n_vocab)\n",
        "        else:\n",
        "            noise_dist = self.noise_dist\n",
        "        noise_words = torch.multinomial(noise_dist,\n",
        "                                        batch_size * n_samples,\n",
        "                                        replacement=True)\n",
        "        \n",
        "        device = \"cuda\" if model.out_embed.weight.is_cuda else \"cpu\"\n",
        "        noise_words = noise_words.to(device)\n",
        "\n",
        "        noise_vector = self.out_embed(noise_words).view(batch_size,n_samples,self.n_embed)        \n",
        "        return noise_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QPbAWnkjWeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NegativeSamplingLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input_vectors, output_vectors, noise_vectors):\n",
        "        \n",
        "        batch_size, embed_size = input_vectors.shape\n",
        "        input_vectors = input_vectors.view(batch_size, embed_size, 1)\n",
        "        output_vectors = output_vectors.view(batch_size, 1, embed_size)\n",
        "\n",
        "        out_loss = torch.bmm(output_vectors, input_vectors).sigmoid().log()\n",
        "        out_loss = out_loss.squeeze()\n",
        "        \n",
        "        noise_loss = torch.bmm(noise_vectors.neg(), input_vectors).sigmoid().log()\n",
        "        noise_loss = noise_loss.squeeze().sum(1)  \n",
        "        return -(out_loss + noise_loss).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8rWgZsLjtfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "word_freqs = np.array(sorted(freqs.values(), reverse=True))\n",
        "unigram_dist = word_freqs/word_freqs.sum()\n",
        "noise_dist = torch.from_numpy(unigram_dist**(0.75)/np.sum(unigram_dist**(0.75)))\n",
        "\n",
        "embedding_dim = 300\n",
        "model = SkipGramNeg(len(vocab_to_int), embedding_dim, noise_dist=noise_dist).to(device)\n",
        "\n",
        "criterion = NegativeSamplingLoss() \n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "print_every = 1500\n",
        "steps = 0\n",
        "epochs = 5\n",
        "\n",
        "for e in range(epochs):\n",
        "    for input_words, target_words in get_batches(train_words, 512):\n",
        "        steps += 1\n",
        "        inputs, targets = torch.LongTensor(input_words), torch.LongTensor(target_words)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        input_vectors = model.forward_input(inputs)\n",
        "        output_vectors = model.forward_output(targets)\n",
        "        noise_vectors = model.forward_noise(inputs.shape[0], 5)\n",
        "\n",
        "        loss = criterion(input_vectors, output_vectors, noise_vectors)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if steps % print_every == 0:\n",
        "            print(\"Epoch: {}/{}\".format(e+1, epochs))\n",
        "            print(\"Loss: \", loss.item()) \n",
        "            valid_examples, valid_similarities = cosine_similarity(model.in_embed, device=device)\n",
        "            _, closest_idxs = valid_similarities.topk(6)\n",
        "\n",
        "            valid_examples, closest_idxs = valid_examples.to('cpu'), closest_idxs.to('cpu')\n",
        "            for ii, valid_idx in enumerate(valid_examples):\n",
        "                closest_words = [int_to_vocab[idx.item()] for idx in closest_idxs[ii]][1:]\n",
        "                print(int_to_vocab[valid_idx.item()] + \" | \" + ', '.join(closest_words))\n",
        "            print(\"...\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_Low58djt5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDR_6dWJDh2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "[(f.name, f.fname) for f in fm.fontManager.ttflist if 'Malgun' in f.name]\n",
        "font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
        "f = [f.name for f in fm.fontManager.ttflist]\n",
        "print(len(font_list))\n",
        "# 10개의 폰트 명 만 출력\n",
        "f[:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsxotCvPks_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting embeddings from the embedding layer of our model, by name\n",
        "embeddings = model.in_embed.weight.to('cpu').data.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3yzUC99kvfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "viz_words = 600\n",
        "tsne = TSNE()\n",
        "embed_tsne = tsne.fit_transform(embeddings[:viz_words, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8W1Oj7zA7YW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import font_manager, rc\n",
        "font_name = font_manager.FontProperties(fname=\"/content/gdirve/My Drive/malgun.ttf\").get_name()\n",
        "rc('font', family=font_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nflHoCBokzUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/gdirve/My Drive/malgun.ttf\"\n",
        "fontprop = fm.FontProperties(fname=path, size=10)\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "fig, ax = plt.subplots(figsize=(16, 16))\n",
        "for idx in range(viz_words):\n",
        "    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n",
        "    plt.annotate(int_to_vocab[idx], (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7, fontproperties=fontprop)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}